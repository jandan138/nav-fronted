import gradio as gr
import requests
import json
import os
import uuid
import time
import subprocess
from typing import Optional, List
from datetime import datetime
import cv2
import numpy as np

# åç«¯APIé…ç½®ï¼ˆå¯é…ç½®åŒ–ï¼‰
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8000")
API_ENDPOINTS = {
    "submit_task": f"{BACKEND_URL}/predict/video",
    "query_status": f"{BACKEND_URL}/predict/task",
    "get_result": f"{BACKEND_URL}//predict"
}

# æ¨¡æ‹Ÿåœºæ™¯é…ç½®
SCENE_CONFIGS = {
    "scene_1": {
        "description": "scene_1",
        "objects": ["bedroom", "kitchen", "living room", ""],
        "preview_image": "/opt/nav-fronted/assets/scene_1.png"
    },
}

MODEL_CHOICES = []  # ä»…å ä½ï¼Œä¸å†ä½¿ç”¨

###############################################################################


# æ—¥å¿—æ–‡ä»¶è·¯å¾„
LOG_DIR = "/opt/nav-frontend/logs"
os.makedirs(LOG_DIR, exist_ok=True)
ACCESS_LOG = os.path.join(LOG_DIR, "access.log")
SUBMISSION_LOG = os.path.join(LOG_DIR, "submissions.log")

def log_access(user_ip: str = None, user_agent: str = None):
    """è®°å½•ç”¨æˆ·è®¿é—®æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = {
        "timestamp": timestamp,
        "type": "access",
        "user_ip": user_ip or "unknown",
        "user_agent": user_agent or "unknown"
    }
    
    with open(ACCESS_LOG, "a") as f:
        f.write(json.dumps(log_entry) + "\n")

def log_submission(scene: str, prompt: str, model: str, user: str = "anonymous", res: str = "unknown"):
    """è®°å½•ç”¨æˆ·æäº¤æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = {
        "timestamp": timestamp,
        "type": "submission",
        "user": user,
        "scene": scene,
        "prompt": prompt,
        "model": model,
        #"max_step": str(max_step),
        "res": res
    }
    
    with open(SUBMISSION_LOG, "a") as f:
        f.write(json.dumps(log_entry) + "\n")

def read_logs(log_type: str = "all", max_entries: int = 50) -> list:
    """è¯»å–æ—¥å¿—æ–‡ä»¶"""
    logs = []
    
    if log_type in ["all", "access"]:
        try:
            with open(ACCESS_LOG, "r") as f:
                for line in f:
                    logs.append(json.loads(line.strip()))
        except FileNotFoundError:
            pass
    
    if log_type in ["all", "submission"]:
        try:
            with open(SUBMISSION_LOG, "r") as f:
                for line in f:
                    logs.append(json.loads(line.strip()))
        except FileNotFoundError:
            pass
    
    # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    logs.sort(key=lambda x: x["timestamp"], reverse=True)
    return logs[:max_entries]

def format_logs_for_display(logs: list) -> str:
    """æ ¼å¼åŒ–æ—¥å¿—ç”¨äºæ˜¾ç¤º"""
    if not logs:
        return "æš‚æ— æ—¥å¿—è®°å½•"
    
    markdown = "### ç³»ç»Ÿè®¿é—®æ—¥å¿—\n\n"
    markdown += "| æ—¶é—´ | ç±»å‹ | ç”¨æˆ·/IP | è¯¦ç»†ä¿¡æ¯ |\n"
    markdown += "|------|------|---------|----------|\n"
    
    for log in logs:
        timestamp = log.get("timestamp", "unknown")
        log_type = "è®¿é—®" if log.get("type") == "access" else "æäº¤"
        
        if log_type == "è®¿é—®":
            user = log.get("user_ip", "unknown")
            details = f"User-Agent: {log.get('user_agent', 'unknown')}"
        else:
            user = log.get("user", "anonymous")
            result = log.get('res', 'unknown')
            if result != "success": 
                if len(result) > 40:  # Adjust this threshold as needed
                    result = f"{result[:20]}...{result[-20:]}"
            details = f"åœºæ™¯: {log.get('scene', 'unknown')}, æŒ‡ä»¤: {log.get('prompt', '')}, æ¨¡å‹: {log.get('model', 'unknown')}, result: {result}"
        
        markdown += f"| {timestamp} | {log_type} | {user} | {details} |\n"
    
    return markdown



###############################################################################


def stream_simulation_results(result_folder: str, task_id: str, fps: int = 30):
    """
    æµå¼è¾“å‡ºä»¿çœŸç»“æœï¼ŒåŒæ—¶ç›‘æ§å›¾ç‰‡æ–‡ä»¶å¤¹å’Œåç«¯ä»»åŠ¡çŠ¶æ€
    
    å‚æ•°:
        result_folder: åŒ…å«ç”Ÿæˆå›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
        task_id: åç«¯ä»»åŠ¡IDç”¨äºçŠ¶æ€æŸ¥è¯¢
        fps: è¾“å‡ºè§†é¢‘çš„å¸§ç‡
        
    ç”Ÿæˆ:
        ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„ (åˆ†æ®µè¾“å‡º)
    """
    # åˆå§‹åŒ–å˜é‡
    result_folder = os.path.join(result_folder, "image")
    os.makedirs(result_folder, exist_ok=True)
    frame_buffer: List[np.ndarray] = []
    frames_per_segment = fps * 2  # æ¯2ç§’60å¸§
    processed_files = set()
    width, height = 0, 0
    last_status_check = 0
    status_check_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡åç«¯çŠ¶æ€
    max_time = 240

    while max_time > 0:
        max_time -= 1
        current_time = time.time()
        
        # å®šæœŸæ£€æŸ¥åç«¯çŠ¶æ€
        if current_time - last_status_check > status_check_interval:
            status = get_task_status(task_id)
            print("status: ", status)
            if status.get("status") == "completed":
                # ç¡®ä¿å¤„ç†å®Œæ‰€æœ‰å·²ç”Ÿæˆçš„å›¾ç‰‡
                process_remaining_images(result_folder, processed_files, frame_buffer)
                if frame_buffer:
                    yield create_video_segment(frame_buffer, fps, width, height)
                break
            elif status.get("status") == "failed":
                raise gr.Error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {status.get('result', 'æœªçŸ¥é”™è¯¯')}")
            last_status_check = current_time

        # å¤„ç†æ–°ç”Ÿæˆçš„å›¾ç‰‡
        current_files = sorted(
            [f for f in os.listdir(result_folder) 
             if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
            key=lambda x: os.path.splitext(x)[0]  # æŒ‰æ–‡ä»¶åæ’åº
        )
        
        new_files = [f for f in current_files if f not in processed_files]
        has_new_frames = False
        
        for filename in new_files:
            try:
                img_path = os.path.join(result_folder, filename)
                frame = cv2.imread(img_path)
                if frame is not None:
                    if width == 0:  # ç¬¬ä¸€æ¬¡è·å–å›¾åƒå°ºå¯¸
                        height, width = frame.shape[:2]
                    
                    frame_buffer.append(frame)
                    processed_files.add(filename)
                    has_new_frames = True
            except Exception as e:
                print(f"Error processing {filename}: {e}")

        # å¦‚æœæœ‰æ–°å¸§ä¸”ç§¯ç´¯å¤Ÿ60å¸§ï¼Œè¾“å‡ºè§†é¢‘ç‰‡æ®µ
        if has_new_frames and len(frame_buffer) >= frames_per_segment:
            segment_frames = frame_buffer[:frames_per_segment]
            frame_buffer = frame_buffer[frames_per_segment:]
            yield create_video_segment(segment_frames, fps, width, height)

        time.sleep(1)  # é¿å…è¿‡äºé¢‘ç¹æ£€æŸ¥
    
    if max_time <= 0:
        raise gr.Error("timeout 240s")

def create_video_segment(frames: List[np.ndarray], fps: int, width: int, height: int) -> str:
    """åˆ›å»ºè§†é¢‘ç‰‡æ®µ"""
    os.makedirs("/opt/gradio_demo/tasks/video_chunk", exist_ok=True)
    segment_name = f"/opt/gradio_demo/tasks/video_chunk/output_{uuid.uuid4()}.mp4"
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(segment_name, fourcc, fps, (width, height))
    
    for frame in frames:
        out.write(frame)
    out.release()
    
    return segment_name

def process_remaining_images(result_folder: str, processed_files: set, frame_buffer: List[np.ndarray]):
    """å¤„ç†å‰©ä½™çš„å›¾ç‰‡"""
    current_files = sorted(
        [f for f in os.listdir(result_folder) 
         if f.lower().endswith(('.png', '.jpg', '.jpeg'))],
        key=lambda x: os.path.splitext(x)[0]
    )
    
    new_files = [f for f in current_files if f not in processed_files]
    
    for filename in new_files:
        try:
            img_path = os.path.join(result_folder, filename)
            frame = cv2.imread(img_path)
            if frame is not None:
                frame_buffer.append(frame)
                processed_files.add(filename)
        except Exception as e:
            print(f"Error processing remaining {filename}: {e}")




###############################################################################

def convert_to_h264(video_path):
    """
    å°†è§†é¢‘è½¬æ¢ä¸º H.264 ç¼–ç çš„ MP4 æ ¼å¼
    ç”Ÿæˆæ–°æ–‡ä»¶è·¯å¾„åœ¨åŸè·¯å¾„åŸºç¡€ä¸Šæ·»åŠ  _h264 åç¼€ï¼‰
    """
    # 
    base, ext = os.path.splitext(video_path)
    video_path_h264 = f"{base}_h264.mp4"

    # è‡ªåŠ¨æŸ¥æ‰¾ ffmpeg å¯æ‰§è¡Œè·¯å¾„
    ffmpeg_bin = "/root/anaconda3/envs/gradio/bin/ffmpeg"
    if not os.path.exists(ffmpeg_bin):
        print("âš ï¸ æ‰¾ä¸åˆ° ffmpegï¼Œè¯·ç¡®ä¿å…¶å·²å®‰è£…å¹¶åœ¨ PATH ä¸­")
        ffmpeg_bin = shutil.which("ffmpeg")
    if ffmpeg_bin is None:
        raise RuntimeError("âŒ æ‰¾ä¸åˆ° ffmpegï¼Œè¯·ç¡®ä¿å…¶å·²å®‰è£…å¹¶åœ¨ PATH ä¸­")

    ffmpeg_cmd = [
        ffmpeg_bin,
        "-i", video_path,
        "-c:v", "libx264",
        "-preset", "slow",
        "-crf", "23",
        "-c:a", "aac",
        "-movflags", "+faststart",
        video_path_h264
    ]

    try:
        print("ğŸš€ æ­£åœ¨æ‰§è¡Œ FFmpeg å‘½ä»¤ï¼š", " ".join(ffmpeg_cmd))
        result = subprocess.run(ffmpeg_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print("âœ… FFmpeg æ‰§è¡Œå®Œæˆ")

        if not os.path.exists(video_path_h264):
            raise FileNotFoundError(f"âš ï¸ H.264 æ–‡ä»¶æœªç”Ÿæˆ: {video_path_h264}")

        print(f"ğŸ‰ è½¬æ¢æˆåŠŸï¼è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼š{video_path_h264}")
        return video_path_h264

    except subprocess.CalledProcessError as e:
        print(f"âŒ FFmpeg æ‰§è¡Œå¤±è´¥:\n{e.stderr.decode(errors='ignore')}")
        raise

    except Exception as e:
        print(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise

def submit_to_backend(
    scene: str,
    prompt: str,
    start_position: str,
    user: str = "Gradio-user",
) -> dict:
    job_id = str(uuid.uuid4())

    #data = {
    #   "scene_type": scene,
    #    "instruction": prompt,
    #    "start_position": start_position,
    #}

    data = {
        "model_type": "rdp",
        
        "instruction": "Exit the bedroom and turn left. Walk straight passing the gray couch and stop near the rug.",
        "episode_type": "demo1",
    }
    
    payload = {
        "user": user,
        "task": "robot_navigation",
        "job_id": job_id,
        "data": json.dumps(data)
    }
    
    try:
        headers = {"Content-Type": "application/json"}
        response = requests.post(
            API_ENDPOINTS["submit_task"],
            json=payload,
            headers=headers,
            timeout=200
        )
        return response.json()
    except Exception as e:
        return {"status": "error", "message": str(e)}

def get_task_status(task_id: str) -> dict:
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    """
    try:
        response = requests.get(
            f"{API_ENDPOINTS['query_status']}/{task_id}",
            timeout=5
        )
        return response.json()
    except Exception as e:
        return {"status": "error", "message": str(e)}

def get_task_result(task_id: str) -> Optional[dict]:
    """
    è·å–ä»»åŠ¡ç»“æœ
    """
    try:
        response = requests.get(
            f"{API_ENDPOINTS['get_result']}/{task_id}",
            timeout=5
        )
        return response.json()
    except Exception as e:
        print(f"Error fetching result: {e}")
        return None

def run_simulation(
    scene: str,
    prompt: str,
    start_position: str,
    history: list
) -> dict:
    """è¿è¡Œä»¿çœŸå¹¶æ›´æ–°å†å²è®°å½•"""
    # è·å–å½“å‰æ—¶é—´
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    scene_desc = SCENE_CONFIGS.get(scene, {}).get("description", scene)

    # è®°å½•ç”¨æˆ·æäº¤
    user_ip = request.client.host if request else "unknown"
    
    # æäº¤ä»»åŠ¡åˆ°åç«¯
    submission_result = submit_to_backend(scene, prompt, start_position)
    
    if submission_result.get("status") != "pending":
        raise gr.Error(f"æäº¤å¤±è´¥: {submission_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
    
    task_id = submission_result["task_id"]

    # è½®è¯¢config
    max_checks = 50  # å¢åŠ æœ€å¤§æ£€æŸ¥æ¬¡æ•°
    initial_delay = 15.0  # åˆå§‹å»¶è¿Ÿ
    max_delay = 3.0  # æœ€ç»ˆå»¶è¿Ÿ
    current_delay = initial_delay
    
    for i in range(max_checks):
        # åœ¨æ£€æŸ¥å‰ç­‰å¾…
        time.sleep(current_delay)
        
        # è·å–ä»»åŠ¡çŠ¶æ€
        status = get_task_status(task_id)
        print("status: ", status)
        if status.get("status") == "completed":
            video_path = os.path.join(status.get("result"), "output.mp4")
            print("video_path: ", video_path)
            video_path = convert_to_h264(video_path)

            # åˆ›å»ºæ–°çš„å†å²è®°å½•æ¡ç›®
            new_entry = {
                "timestamp": timestamp,
                "scene": scene,
                "start_pos": start_position,
                "prompt": prompt,
                "video_path": video_path
            }
            
            # å°†æ–°æ¡ç›®æ·»åŠ åˆ°å†å²è®°å½•é¡¶éƒ¨
            updated_history = history + [new_entry]
            
            # é™åˆ¶å†å²è®°å½•æ•°é‡ï¼Œé¿å…å†…å­˜é—®é¢˜
            if len(updated_history) > 10:
                updated_history = updated_history[:10]
            
            print("updated_history:", updated_history)
            
            return video_path, updated_history

        elif status.get("status") == "failed":
            print(f"âŒ Task ID å¤±è´¥: {task_id}")
            print(f"âŒ åç«¯è¿”å›ä¿¡æ¯: {status}")
            raise gr.Error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {status.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return None, history
        
        current_delay = max(current_delay * 0.8, max_delay)
    
    raise gr.Error(f"ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ï¼Œè¶…è¿‡æœ€å¤§ç­‰å¾…æ—¶é—´({max_checks * max_delay:.0f}ç§’)")
    return None, history

def update_history_display(history: list) -> list:
    updates = []
    
    for i in range(10):
        if i < len(history):
            entry = history[i]
            updates.extend([
                gr.update(visible=True),
                gr.update(visible=True, label=f"ä»¿çœŸè®°å½• {i+1}  scene: {entry['scene']}, start: {entry['start_pos']}, prompt: {entry['prompt']}", open=False),
                gr.update(value=entry['video_path'], visible=True),
                gr.update(value=f"{entry['timestamp']}")
            ])
        else:
            updates.extend([
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(value=None, visible=False),
                gr.update(value="")
            ])
    
    return updates

def update_scene_display(scene: str) -> tuple[str, Optional[str]]:
    config = SCENE_CONFIGS.get(scene, {})
    desc = config.get("description", "æ— æè¿°")
    objects = "ã€".join(config.get("objects", []))
    image = config.get("preview_image", None)
    
    markdown = f"**{desc}**  \nåŒ…å«åœ°ç‚¹: {objects}"
    return markdown, image

custom_css = """
#simulation-panel {
    border-radius: 8px;
    padding: 20px;
    background: #f9f9f9;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}
#result-panel {
    border-radius: 8px;
    padding: 20px;
    background: #f0f8ff;
}
.dark #simulation-panel { background: #2a2a2a; }
.dark #result-panel { background: #1a2a3a; }

.history-container {
    max-height: 600px;
    overflow-y: auto;
    margin-top: 20px;
}

.history-accordion {
    margin-bottom: 10px;
}
"""

with gr.Blocks(title="æœºå™¨äººå¯¼èˆªè®­ç»ƒç³»ç»Ÿ", css=custom_css) as demo:
    gr.Markdown("""
    # ğŸ§­ IsaacSim æœºå™¨äººå¯¼èˆªæ¼”ç¤º
    ### åŸºäºGRNavigationæ¡†æ¶çš„ä»¿çœŸå¯¼èˆªæµ‹è¯•
    """)
    
    history_state = gr.State([])

    with gr.Row():
        with gr.Column(elem_id="simulation-panel"):
            gr.Markdown("### ä»¿çœŸä»»åŠ¡é…ç½®")
            
            scene_dropdown = gr.Dropdown(
                label="é€‰æ‹©åœºæ™¯é…ç½®",
                choices=list(SCENE_CONFIGS.keys()),
                value="scene_1",
                interactive=True
            )
            
            scene_description = gr.Markdown("")
            scene_preview = gr.Image(
                label="åœºæ™¯é¢„è§ˆ",
                elem_classes=["scene-preview"],
                interactive=False
            )
            
            scene_dropdown.change(
                update_scene_display,
                inputs=scene_dropdown,
                outputs=[scene_description, scene_preview]
            )
            
            prompt_input = gr.Textbox(
                label="å¯¼èˆªæŒ‡ä»¤",
                value="Exit the bedroom and turn left. Walk straight passing the gray couch and stop near the rug.",
                placeholder="ä¾‹å¦‚: 'Exit the bedroom and turn left. Walk straight passing the gray couch and stop near the rug.'",
                lines=2,
                max_lines=4
            )
            
            start_pos_input = gr.Textbox(
                label="èµ·å§‹åæ ‡ (x, y, z)",
                value="0.0, 0.0, 0.2",
                placeholder="ä¾‹å¦‚: 0.0, 0.0, 0.2"
            )
            
            submit_btn = gr.Button("å¼€å§‹å¯¼èˆªä»¿çœŸ", variant="primary")
        
        with gr.Column(elem_id="result-panel"):
            gr.Markdown("### æœ€æ–°ä»¿çœŸç»“æœ")
            
            video_output = gr.Video(
                label="å¯¼èˆªè¿‡ç¨‹å›æ”¾",
                interactive=False,
                format="mp4",
                autoplay=True
            )
            
            with gr.Column() as history_container:
                gr.Markdown("### å†å²è®°å½•")
                history_slots = []
                for i in range(10):
                    with gr.Column(visible=False) as slot:
                        with gr.Accordion(visible=False, open=False) as accordion:
                            video = gr.Video(interactive=False)
                            detail_md = gr.Markdown()
                    history_slots.append((slot, accordion, video, detail_md))

    gr.Examples(
        examples=[
            ["scene_1", "Exit the bedroom and turn left. Walk straight passing the gray couch and stop near the rug.", "0.0, 0.0, 0.2"]
        ],
        inputs=[scene_dropdown, prompt_input, start_pos_input],
        label="å¯¼èˆªä»»åŠ¡ç¤ºä¾‹"
    )
    
    submit_btn.click(
        fn=run_simulation,
        inputs=[scene_dropdown, prompt_input, start_pos_input, history_state],
        outputs=[video_output, history_state],
        api_name="run_simulation"
    ).then(
        fn=update_history_display,
        inputs=history_state,
        outputs=[comp for slot in history_slots for comp in slot]
    )
    
    demo.load(
        fn=lambda: update_scene_display("scene_1"),
        outputs=[scene_description, scene_preview]
    )

    demo.queue(default_concurrency_limit=8)

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=55005, share=False, debug=True, allowed_paths=["/opt"])
