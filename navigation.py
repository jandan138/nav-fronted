import gradio as gr
import requests
import json
import os
import uuid
import time
import subprocess
from typing import Optional
from datetime import datetime

# åç«¯APIé…ç½®ï¼ˆå¯é…ç½®åŒ–ï¼‰
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8000")
API_ENDPOINTS = {
    "submit_task": f"{BACKEND_URL}/predict/video",
    "query_status": f"{BACKEND_URL}/predict/task",
    "get_result": f"{BACKEND_URL}//predict"
}

# æ¨¡æ‹Ÿåœºæ™¯é…ç½®
SCENE_CONFIGS = {
    "scene_1": {
        "description": "scene_1",
        "objects": ["ç•ªèŒ„é…±", "ç›ç“¶", "é¤åˆ€", "æ¯å­"],
        "preview_image": "/opt/nav-fronted/assets/scene_1.png"
    },
}

MODEL_CHOICES = []  # ä»…å ä½ï¼Œä¸å†ä½¿ç”¨

def convert_to_h264(video_path):
    """
    å°†è§†é¢‘è½¬æ¢ä¸º H.264 ç¼–ç çš„ MP4 æ ¼å¼
    ç”Ÿæˆæ–°æ–‡ä»¶è·¯å¾„åœ¨åŸè·¯å¾„åŸºç¡€ä¸Šæ·»åŠ  _h264 åç¼€ï¼‰
    """
    # 
    base, ext = os.path.splitext(video_path)
    video_path_h264 = f"{base}_h264.mp4"

    # è‡ªåŠ¨æŸ¥æ‰¾ ffmpeg å¯æ‰§è¡Œè·¯å¾„
    ffmpeg_bin = "/root/anaconda3/envs/gradio/bin/ffmpeg"
    if not os.path.exists(ffmpeg_bin):
        print("âš ï¸ æ‰¾ä¸åˆ° ffmpegï¼Œè¯·ç¡®ä¿å…¶å·²å®‰è£…å¹¶åœ¨ PATH ä¸­")
        ffmpeg_bin = shutil.which("ffmpeg")
    if ffmpeg_bin is None:
        raise RuntimeError("âŒ æ‰¾ä¸åˆ° ffmpegï¼Œè¯·ç¡®ä¿å…¶å·²å®‰è£…å¹¶åœ¨ PATH ä¸­")

    ffmpeg_cmd = [
        ffmpeg_bin,
        "-i", video_path,
        "-c:v", "libx264",
        "-preset", "slow",
        "-crf", "23",
        "-c:a", "aac",
        "-movflags", "+faststart",
        video_path_h264
    ]

    try:
        print("ğŸš€ æ­£åœ¨æ‰§è¡Œ FFmpeg å‘½ä»¤ï¼š", " ".join(ffmpeg_cmd))
        result = subprocess.run(ffmpeg_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print("âœ… FFmpeg æ‰§è¡Œå®Œæˆ")

        if not os.path.exists(video_path_h264):
            raise FileNotFoundError(f"âš ï¸ H.264 æ–‡ä»¶æœªç”Ÿæˆ: {video_path_h264}")

        print(f"ğŸ‰ è½¬æ¢æˆåŠŸï¼è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼š{video_path_h264}")
        return video_path_h264

    except subprocess.CalledProcessError as e:
        print(f"âŒ FFmpeg æ‰§è¡Œå¤±è´¥:\n{e.stderr.decode(errors='ignore')}")
        raise

    except Exception as e:
        print(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise

def submit_to_backend(
    scene: str,
    prompt: str,
    start_position: str,
    user: str = "Gradio-user",
) -> dict:
    job_id = str(uuid.uuid4())

    #data = {
    #   "scene_type": scene,
    #    "instruction": prompt,
    #    "start_position": start_position,
    #}

    data = {
        "model_type": "rdp",
        
        "instruction": "Exit the bedroom and turn left. Walk straight passing the gray couch and stop near the rug.",
        "episode_type": "demo1",
    }
    
    payload = {
        "user": user,
        "task": "robot_navigation",
        "job_id": job_id,
        "data": json.dumps(data)
    }
    
    try:
        headers = {"Content-Type": "application/json"}
        response = requests.post(
            API_ENDPOINTS["submit_task"],
            json=payload,
            headers=headers,
            timeout=200
        )
        return response.json()
    except Exception as e:
        return {"status": "error", "message": str(e)}

def get_task_status(task_id: str) -> dict:
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    """
    try:
        response = requests.get(
            f"{API_ENDPOINTS['query_status']}/{task_id}",
            timeout=5
        )
        return response.json()
    except Exception as e:
        return {"status": "error", "message": str(e)}

def get_task_result(task_id: str) -> Optional[dict]:
    """
    è·å–ä»»åŠ¡ç»“æœ
    """
    try:
        response = requests.get(
            f"{API_ENDPOINTS['get_result']}/{task_id}",
            timeout=5
        )
        return response.json()
    except Exception as e:
        print(f"Error fetching result: {e}")
        return None

def run_simulation(
    scene: str,
    prompt: str,
    start_position: str,
    history: list
) -> dict:
    """è¿è¡Œä»¿çœŸå¹¶æ›´æ–°å†å²è®°å½•"""
    # è·å–å½“å‰æ—¶é—´
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    scene_desc = SCENE_CONFIGS.get(scene, {}).get("description", scene)
    
    # æäº¤ä»»åŠ¡åˆ°åç«¯
    submission_result = submit_to_backend(scene, prompt, start_position)
    
    if submission_result.get("status") != "pending":
        raise gr.Error(f"æäº¤å¤±è´¥: {submission_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
    
    task_id = submission_result["task_id"]

    # è½®è¯¢config
    max_checks = 50  # å¢åŠ æœ€å¤§æ£€æŸ¥æ¬¡æ•°
    initial_delay = 15.0  # åˆå§‹å»¶è¿Ÿ
    max_delay = 3.0  # æœ€ç»ˆå»¶è¿Ÿ
    current_delay = initial_delay
    
    for i in range(max_checks):
        # åœ¨æ£€æŸ¥å‰ç­‰å¾…
        time.sleep(current_delay)
        
        # è·å–ä»»åŠ¡çŠ¶æ€
        status = get_task_status(task_id)
        print("status: ", status)
        if status.get("status") == "completed":
            video_path = os.path.join(status.get("result"), "output.mp4")
            print("video_path: ", video_path)
            video_path = convert_to_h264(video_path)

            # åˆ›å»ºæ–°çš„å†å²è®°å½•æ¡ç›®
            new_entry = {
                "timestamp": timestamp,
                "scene": scene,
                "start_pos": start_position,
                "prompt": prompt,
                "video_path": video_path
            }
            
            # å°†æ–°æ¡ç›®æ·»åŠ åˆ°å†å²è®°å½•é¡¶éƒ¨
            updated_history = history + [new_entry]
            
            # é™åˆ¶å†å²è®°å½•æ•°é‡ï¼Œé¿å…å†…å­˜é—®é¢˜
            if len(updated_history) > 10:
                updated_history = updated_history[:10]
            
            print("updated_history:", updated_history)
            
            return video_path, updated_history

        elif status.get("status") == "failed":
            print(f"âŒ Task ID å¤±è´¥: {task_id}")
            print(f"âŒ åç«¯è¿”å›ä¿¡æ¯: {status}")
            raise gr.Error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {status.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return None, history
        
        current_delay = max(current_delay * 0.8, max_delay)
    
    raise gr.Error(f"ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ï¼Œè¶…è¿‡æœ€å¤§ç­‰å¾…æ—¶é—´({max_checks * max_delay:.0f}ç§’)")
    return None, history

def update_history_display(history: list) -> list:
    updates = []
    
    for i in range(10):
        if i < len(history):
            entry = history[i]
            updates.extend([
                gr.update(visible=True),
                gr.update(visible=True, label=f"ä»¿çœŸè®°å½• {i+1}  scene: {entry['scene']}, start: {entry['start_pos']}, prompt: {entry['prompt']}", open=False),
                gr.update(value=entry['video_path'], visible=True),
                gr.update(value=f"{entry['timestamp']}")
            ])
        else:
            updates.extend([
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(value=None, visible=False),
                gr.update(value="")
            ])
    
    return updates

def update_scene_display(scene: str) -> tuple[str, Optional[str]]:
    config = SCENE_CONFIGS.get(scene, {})
    desc = config.get("description", "æ— æè¿°")
    objects = "ã€".join(config.get("objects", []))
    image = config.get("preview_image", None)
    
    markdown = f"**{desc}**  \nåŒ…å«ç‰©ä½“: {objects}"
    return markdown, image

custom_css = """
#simulation-panel {
    border-radius: 8px;
    padding: 20px;
    background: #f9f9f9;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}
#result-panel {
    border-radius: 8px;
    padding: 20px;
    background: #f0f8ff;
}
.dark #simulation-panel { background: #2a2a2a; }
.dark #result-panel { background: #1a2a3a; }

.history-container {
    max-height: 600px;
    overflow-y: auto;
    margin-top: 20px;
}

.history-accordion {
    margin-bottom: 10px;
}
"""

with gr.Blocks(title="æœºå™¨äººå¯¼èˆªè®­ç»ƒç³»ç»Ÿ", css=custom_css) as demo:
    gr.Markdown("""
    # ğŸ§­ IsaacSim æœºå™¨äººå¯¼èˆªæ¼”ç¤º
    ### åŸºäºGRNavigationæ¡†æ¶çš„ä»¿çœŸå¯¼èˆªæµ‹è¯•
    """)
    
    history_state = gr.State([])

    with gr.Row():
        with gr.Column(elem_id="simulation-panel"):
            gr.Markdown("### ä»¿çœŸä»»åŠ¡é…ç½®")
            
            scene_dropdown = gr.Dropdown(
                label="é€‰æ‹©åœºæ™¯é…ç½®",
                choices=list(SCENE_CONFIGS.keys()),
                value="scene_1",
                interactive=True
            )
            
            scene_description = gr.Markdown("")
            scene_preview = gr.Image(
                label="åœºæ™¯é¢„è§ˆ",
                elem_classes=["scene-preview"],
                interactive=False
            )
            
            scene_dropdown.change(
                update_scene_display,
                inputs=scene_dropdown,
                outputs=[scene_description, scene_preview]
            )
            
            prompt_input = gr.Textbox(
                label="å¯¼èˆªæŒ‡ä»¤",
                value="Exit the bedroom and turn left. Walk straight passing the gray couch and stop near the rug.",
                placeholder="ä¾‹å¦‚: 'Exit the bedroom and turn left. Walk straight passing the gray couch and stop near the rug.'",
                lines=2,
                max_lines=4
            )
            
            start_pos_input = gr.Textbox(
                label="èµ·å§‹åæ ‡ (x, y, z)",
                value="0.0, 0.0, 0.2",
                placeholder="ä¾‹å¦‚: 0.0, 0.0, 0.2"
            )
            
            submit_btn = gr.Button("å¼€å§‹å¯¼èˆªä»¿çœŸ", variant="primary")
        
        with gr.Column(elem_id="result-panel"):
            gr.Markdown("### æœ€æ–°ä»¿çœŸç»“æœ")
            
            video_output = gr.Video(
                label="å¯¼èˆªè¿‡ç¨‹å›æ”¾",
                interactive=False,
                format="mp4",
                autoplay=True
            )
            
            with gr.Column() as history_container:
                gr.Markdown("### å†å²è®°å½•")
                history_slots = []
                for i in range(10):
                    with gr.Column(visible=False) as slot:
                        with gr.Accordion(visible=False, open=False) as accordion:
                            video = gr.Video(interactive=False)
                            detail_md = gr.Markdown()
                    history_slots.append((slot, accordion, video, detail_md))

    gr.Examples(
        examples=[
            ["scene_1", "Navigate to the ketchup bottle while avoiding the knife.", "0.0, 0.0, 0.2"]
        ],
        inputs=[scene_dropdown, prompt_input, start_pos_input],
        label="å¯¼èˆªä»»åŠ¡ç¤ºä¾‹"
    )
    
    submit_btn.click(
        fn=run_simulation,
        inputs=[scene_dropdown, prompt_input, start_pos_input, history_state],
        outputs=[video_output, history_state],
        api_name="run_simulation"
    ).then(
        fn=update_history_display,
        inputs=history_state,
        outputs=[comp for slot in history_slots for comp in slot]
    )
    
    demo.load(
        fn=lambda: update_scene_display("scene_1"),
        outputs=[scene_description, scene_preview]
    )

    demo.queue(default_concurrency_limit=8)

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=55005, share=False, debug=True, allowed_paths=["/opt"])
